---
title: "Actividad: PRA2: Limpieza y análisis de datos"
author: "Reison A. Torres Urina"
date: "Diciembre 2019"
header-includes:
  - \usepackage[spanish]{babel}
output: 
  html_document:
    includes:
      in_header: PRA2-header.html
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
  word_document: default
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Detalles de la actividad  

## Descripción  

En esta practica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.  

## Objetivos

Los objetivos concretos de esta práctica son:  

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de
problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o
multidisciplinares.  

* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza
y validación) para llevar a cabo un proyecto analítico.  

* Aprender a analizar los datos adecuadamente para abordar la información contenida en
los datos.  

* Identificar la mejor representación de los resultados para aportar conclusiones sobre el
problema planteado en el proceso analítico.  

* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.  

* Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.  

* Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.

## Competencias

En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:  

* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación
y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.  

* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración,
transformación, limpieza y validación) para su posterior análisis.  

# Solución

## Descripción del dataset  

### Carga de los datos

Cargamos el conjunto de datos que se encuentran en los archivos __train.csv__, __test.csv__ y __gender_submission.csv__ en formato CSV, y representan los datos de los pasajeros que abordaron el Titanic.

Estos datos estarán representados en R por un dataframe para facilitar la manipulación de los mismos en nuestro análisis.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# cargamos paquetes R que vamos a utilizar durante nuestro anlisis
  
if(!require(ggplot2)){
    #install.packages('ggplot2', repos='http://cran.us.r-project.org')
    library(ggplot2)
}

if(!require(ggpubr)){
    #install.packages('ggpubr', repos='http://cran.us.r-project.org')
    library(ggpubr)
}

library(dplyr)
#library(Hmisc)
#library(corrplot)

# Carga del dataset contenido en el archivo train.csv
titanic.train <- read.csv("../datos/train.csv",stringsAsFactors = FALSE, header=T, sep=",")
# Carga del dataset contenido en el archivo test.csv
titanic.test <- read.csv("../datos/test.csv",stringsAsFactors = FALSE, header=T, sep=",")
# Carga del dataset contenido en el archivo gender_submission.csv
titanic.test.survived <- read.csv("../datos/gender_submission.csv",stringsAsFactors = FALSE, header=T, sep=",")

```

### Descripción

Los datos seleccionados, fueron obtenidos del sitio de data science, [__www.Kaggle.com__](https://www.kaggle.com), en el encontramos una variedad de dataset Open Data. El conjunto de datos seleccionados para desarrollar esta actividad es [__Titanic: Machine Learning from Disaster__](https://www.kaggle.com/c/titanic), en este dataset encontramos, los datos de los pasajeros, que abordaron el Titanic en su viaje inaugural.

Los datos de este dataset se encuentran divididos en dos archivos train.csv con 891 observaciones y test.cvs con 418 observaciones para un total de 1309. El conjunto de datos esta descripto por un conjunto de 12 variables. Las característica presenten en este dataset, nos permitirá cumplir los objetivos propuestos en esta actividad. 

Variables contenidas en el dataset __train.csv__:  
```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(titanic.train)
```

Variables contenidas en el dataset __test.cvs__:  
```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(titanic.test)
```

Variables contenidas en el dataset __gender_submission.csv__:  
```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(titanic.test.survived)
```  

Este dataset __gender_submission.csv__ contiene la variable de survived, que luego utilizaremos para agregar al dataset __titanic.test__.

A continuación describimos el conjunto de variables que conforman este dataset:  

* __PassengerId:__ Número consecutivo que identifica al pasajero.    
* __Name:__ Nombre del pasajero.
* __Sex:__ Define el xeso del pasajero.   
* __pclass:__ Nivel socioeconómico del pasajero (1st = Upper, 2nd = Middle, 3rd = Lower).  
* __age:__ Edad del pasajero en años.  
* __sibsp:__ Familiar abordo del Titanic. Define la relación familiar de la siguiente forma:  
 : Hermanos => 1 = hermana, 2 = hermano, 3 = hermanastro, 4 = hermanastra  
 : Esposos => 5 = esposo, 6 = esposa, 7 = amantes y 8 = novio  
* __parch:__ Familiar abordo del Titanic. Define la relación familiar de la siguiente forma:  
 : Padres => 1 = madre, 2 = padre  
 : Hijos => 3 = hija, 4 = hijo, 5 = hijastra, 6 = hijastro  
* __ticket:__ Número del boleto de abordaje.  
* __fare:__ Precio del boleto.  
* __cabin:__ Número de la cabina.  
* __embarked:__ Puerto de embarque (C = Cherbourg, Q = Queenstown, S = Southampton).  
* __survived:__ Pasajero superviviente (0 = No, 1 = Yes)


### Importancia y objetivos de los análisis


A partir de este conjunto de datos se plantea la problemática de determinar qué variables influyen más en la supervivencia de un pasajero en el naufragio del Titanic. Además, se podrá proceder a crear modelos de regresión  que permitan predecir si un pasajero sobrevive o no en función de sus características y contrastes de hipótesis que ayuden a identificar propiedades interesantes en las muestras que puedan ser inferidas con respecto a la población.  

Este tipo de análisis pueden ser utilizados por las aseguradoras del sector turístico, para determinar el riesgo que puede tener un turista al viajar en los trasatlánticos. Y asi poder ofreser las cobertura del seguro.

## Integración y selección de los datos de interés a analizar


### Integración

Con el fin de tener una estructura de datos coherente y única que contenga mayor cantidad de información, combinaremos los datos procedentes de los dataset train.csv y test.cvs. Luego realizaremos una fusión horizontal para añadir el atributo **survived**, debido a que el dataset **test.cvs** no presenta este atributo. Este valor será extraído  del dataset **gender_submission.csv**.


```{r echo=TRUE, message=FALSE, warning=FALSE}

# Realizamos una fusión horizontal entre los dataset titanic.test y titanic.test.survived para agregar el atributo survived
titanic.test <- inner_join(titanic.test, titanic.test.survived, by ="PassengerId")

#Creamos el dataset titanic.data con la combinacion de los datos de los dataset  titanic.train y titanic.test
titanic.data <- bind_rows(titanic.train,titanic.test) 

# Eliminamos los dataset temporales
rm(titanic.test.survived)
rm(titanic.test)
rm(titanic.train)

# Verificamos la estructura del dataset con los datos combinados
summary(titanic.data)
```

### Selección de los datos

La gran mayoría de las variables contenidas en el conjunto de datos corresponde con características de los pasajeros que abordaron el Titanic, por lo que serán tenidas en cuenta para realizar nuestro análisis. Sin embargo, podremos prescindir de las variables (**PassengerId**,**Name** y **Ticket**) dado que estos atributos no aportan una carasterisitica al pasajero, y no influye en la resolución de nuestro problema.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Eliminamos del dataset las variables "PassengerId" y "Name"
titanic.data <- titanic.data[,!(colnames(titanic.data) %in% c("PassengerId","Name","Ticket"))]

# Verificamos la estructura del dataset
summary(titanic.data)
```

## Limpieza de los datos

### Discretización y conversion de tipos de datos

Al cargar los archivos con la función read.csv(), esta de manera automática asigna el tipo de variable en el dataset, en ciertas ocasiones los tipos asignados, no son los correctos. A continuación visualizamos los tipos de variables asignados al dataset, para luego decidir si se requiere una conversión de tipo.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Tipos de variables
titanic.data.ctype <- sapply(titanic.data,class)

titanic.data.ctype <- data.frame(variables = names(titanic.data.ctype),tipo = as.vector(titanic.data.ctype),stringsAsFactors = F)

titanic.data.ctype
rm(titanic.data.ctype)
```

En este paso realizamos un analisis sobre las variables, que en R han sido cargadas como continuas pero en realidad son discretas (factor).Para esto realizamos un análisis de discretizacion sobre los atributos, para identificar que variables tienen sentido discretizar.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#summary(titanic.data[,titanic.data.ctype[titanic.data.ctype$tipo == "numeric",]$variables])
# Identificar el número de clases que se encuentra en cada variable del dataset
apply(titanic.data,2, function(x) length(unique(x)))

```

Con el fin de facilitar la interpretar y comparar los resultados de diferentes grupos de datos, procedemos a discretizar a las variables con pocas clases:

```{r echo=TRUE, message=FALSE, warning=FALSE}

cols<-c("Survived","Pclass","Sex","SibSp","Parch","Embarked")
for (i in cols){
  titanic.data[,i] <- as.factor(titanic.data[,i]) # Conversion de variable a tipo factor
}

levels(titanic.data[,"Survived"]) <- c("No","Si") 
levels(titanic.data[,"Pclass"]) <- c("Upper","Middle", "Lower")
levels(titanic.data[,"Embarked"]) <- c("?","Cherbourg", "Queenstown", "Southampton")

summary(titanic.data)
```

### Tratamientos de ceros o elementos vacíos

Los datos vacíos o no definidos pueden presentarse en distintos formatos, típicamente “”, ? ,“ “ o NA (Not Available en inglés), pero en algunos contextos pueden incluso tomar valores numéricos como 0 o 999.

A continuación inspeccionaremos, que atributos de nuestro dataset, tienen una cantidad alta de valores no disponibles o valores faltantes en los diferentes formatos  ("",?, " " o NA):


```{r echo=TRUE, message=FALSE, warning=FALSE}

# Funcion: Explorar atributos con valores faltante
# Parmetros:
# 1. dataset: conjunto de datos con los atributos a explorar
hasValoresFaltantes <- function(dataset){
  # Verificar si existen variables cuantitativas con valores NA
  variablesWithNA <- colSums(is.na(dataset))
  
  # Verificar si existen variables con cadenas vacias
  variablesWithEmpaty <- colSums(dataset=="")
  variablesWithEmpaty[is.na(variablesWithEmpaty)] <- 0
  
  # Verificar si existen variables con valores desconocidos ("?").
  variablesWithQuestionMark <- colSums(dataset=="?")
  variablesWithQuestionMark[is.na(variablesWithQuestionMark)] <- 0
  
  # Verificar si existen variables con valores desconocidos (" ").
  variablesWithSpace <- colSums(dataset==" ")
  variablesWithSpace[is.na(variablesWithSpace)] <- 0
  
  df <- data.frame(variables = names(variablesWithNA),"NA" = as.vector(variablesWithNA),stringsAsFactors = F)
  
  df = bind_cols(df,"Empaty" = as.vector(variablesWithEmpaty))
  df = bind_cols(df,"?" = as.vector(variablesWithQuestionMark))
  df = bind_cols(df,"Space" = as.vector(variablesWithSpace))
  
  df 
  #ls <- list(valoresFaltantes = df);
  #ls$totalMuestras <- dim(dataset)[1]
  #ls
}


```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Verificar si existen variables con valores faltantes
hasValoresFaltantes(titanic.data)

```

Al observar el resultado del análisis anterior, podemos identificar que para las variables Age y Fare presenta  valores faltantes (NA). Para la variable Cabin se identifica que presenta una cantidad alta de valores faltantes en el formato vacío (""). y para la variable Embarked se identifica valores faltantes en el formato "?".

Llegados a este punto debemos decidir cómo manejar estos registros que contienen valores desconocidos:

Para el  atributo __Embarked__ realizamos un análisis de proporción de valores faltantes y lo actualizaremos en función del valor mas frecuente. Existen 2 casos con valor faltante con formato "?", con una proporción del 0.15%, el valor más frecuentes es "Southampton" con una proporción del 56.98% .


```{r echo=TRUE, message=FALSE, warning=FALSE}
arrange(data.frame(round(prop.table(table(titanic.data$Embarked)),4)*100),-Freq)

# actualizamos los valores faltantes con el valor más frecuente
titanic.data$Embarked[titanic.data$Embarked=="?"] <- "Southampton"

```

Para el  atributo __Cabin__ realizamos un análisis de proporción de valores faltantes. Existen 1014 casos con valor faltante con formato vacío (""), con una proporción del 77.46%, esto corresponde a más de la mitad de las observaciones. Si intentamos completar los valores faltantes, por alguna de las técnicas de imputación de valores perdidos, debido a la alta cantidad de valores faltantes en este atributo, nos puede generar sesgos en los datos de este atributo. De acuerdo a esto, se decide eliminar el atributo __Cabin__ del dataset en estudio.


```{r echo=TRUE, message=FALSE, warning=FALSE}
data.frame(Total=sort(colSums(titanic.data == ""), decreasing = TRUE),
           Porcentaje = sort(round(colMeans(titanic.data == "")*100, digits = 2), decreasing = TRUE))["Cabin",]

# Eliminamos la variable Cabin
titanic.data <- titanic.data[, !(names(titanic.data) %in% c("Cabin"))]

```

Como podemos observar las variables __SibSp__, __Parch__ y __Fare__, presenta datos con valores igual a cero, pero para las variables __SibSp__, __Parch__ este valor cero significa que no tienen familiares abordo, de acuerdo a esto el valor cero tiene significado para los datos, y no serán gestionados.

Para la variable __Fare__ los valores ceros podria significar un error de datos faltantes, ya que tienen un numero de ticket asignado, o tambien podriamos decir que este cero equivale a que estos ticket fueron entregados por un premio. Para esta actividad asumiremos que es un error y lo consideraremos como valores faltantes.

Calculamos la proporciona de valores ceros en la variable __Fare__, y los remplazamos por el formato de valor faltante (NA), para luego predecir estos valores con el método kNN. Existen 17 casos con valor faltante con formato vacío (0), con una proporción del 1.3%.

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Proporcion en 
data.frame(Var = c("Fare"),
           Total = length(titanic.data$Fare[titanic.data$Fare == 0 & !is.na(titanic.data$Fare)]),
           Porcentaje = round((length(titanic.data$Fare[titanic.data$Fare == 0 & !is.na(titanic.data$Fare)])/dim(titanic.data)[1])*100,2))

titanic.data$Fare [titanic.data$Fare == 0 & !is.na(titanic.data$Fare)]<- NA


```
Para los  atributo __Fare__ y __Age__ realizamos un análisis de proporción de valores faltantes. Para el caso del atributo __Fare__, existe 18 caso con valor faltante con formato vacío (NA), con una proporción del 1.38%; Y para el atributo __Age__, existe 263 casos con valores faltantes con formato vacío (NA), con una proporción del 20.09%; Debido a que los datos presente en esta variable están un poco dispersos, utilizaremos métodos probalísticos para predecir los valores faltantes.


```{r echo=TRUE, message=FALSE, warning=FALSE}
#library(VIM)
if(!require(VIM)){
    #install.packages('VIM', repos='http://cran.us.r-project.org')
    library(VIM)
}
data.frame(Total=sort(colSums(is.na(titanic.data)), decreasing = TRUE),Porcentaje = sort(round(colMeans(is.na(titanic.data))*100, digits = 2), decreasing = TRUE))[c("Fare","Age"),]

# Para predecir los valores faltantes utilizaremos el metodo kNN
titanic.data.imp <- kNN(titanic.data)

# Imputamos los valores faltantes
titanic.data$Age <- titanic.data.imp$Age # Age
titanic.data$Fare <- titanic.data.imp$Fare #Fare
rm(titanic.data.imp)
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Verificar si existen variables con valores faltantes
hasValoresFaltantes(titanic.data)

```



### Identificación y tratamiento de valores extremos

Los valores extremos (outliers) son aquellos datos que se encuentran muy alejados de la distribución normal de una variable o población. Con este análisis queremos identificar si el dataset contiene observaciones que están alejadas de su distribución normal, con el fin de evitar que estos valores puedan afectar de forma adversa los resultados de los análisis posteriores, al incrementar el error en la varianza de los datos y sesgar significativamente los cálculos y estimaciones.

Para identificar estos valores en el dataset, realizaremos un análisis por cuartiles, para las variables __Age__ y __Fare__. Debido a que el resto de variables pueden ser de tipo categóricas o texto no las incluiremos en este análisis.

Realizaremos un análisis de valores extremos para la variable numérica __Age__, realizando un análisis por quartiles:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# generar los quartiles que representan la distribución del conjunto de datos
summary(titanic.data$Age)

## Calculamos la relación inter quartil (IQR), Q3 - Q1 = IQR()
print(paste("Relación inter quartil (IQR): ",IQR(titanic.data$Age)),quote = FALSE)

# Grafico de boxplot
gf.boxplot <- boxplot(titanic.data$Age, main="Boxplot de la edad (Age)",
ylab="Age",col = "bisque")
```

Al inspeccionar las estadísticas arrojadas, para la variable __Age__, el valor mínimo es 0.17 y el Máximo es 80. Si analisamos  la diferencia entre Q1 y el Mínimo es de 20.83, y la diferencia entre Q3 y el Máximo es 42; cómo podemos ver la diferencia de Q3 y el máximo es mayor que la diferencias entre Q1 y el mínimo. Estos nos indican que el 25% de los valores superiores es tan más dispersos, que el 75% restante.

Al analizar el grafico de diagrama de cajas (Boxplot), se observa que no hay valores atípicos en el extremo inferior, y por eso el bigote inferior se extiende hasta el valor mínimo, 0.17. En cambio en el extremo superior vemos varios valores atípicos, representados por unos círculos sobre el bigote superior.  

Para detectar los valores atípicos, los bigotes se extendieron hasta un $Mínimo = Q1 - 1.5*IQR$, por debajo de Q1 y hasta un $Máximo = Q3 + 1.5*IQR$, por encima de Q3. Donde __IQR = 17__, __Q1 = 21__ y __Q3 = 38__; Entonces el $Mínimo=21–1.5*17=-4.5$, donde todos los valores menores a este valor son considerados atípicos, en nuestro caso como no hay valores menores que este, por eso el bigote se extiende hasta el mínimo valor de la variable; Los valores mayores al $Máximo=38+1.5*17=63.5$ serán considerados atípicos, que son los valores representados en el grafico por los puntos negros.  

Considerando lo anterior, a continuación se muestran los valores atípicos para la variable __Age__. __Donde Age > 63.5__:

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Valores extremos encontrados en la variable Age donde Age > 63.5
sort(gf.boxplot$out, decreasing = FALSE)

```

No obstante, si revisamos los anteriores datos, las edades de los pasajeros comprendidas entre 64 y 80, son valores que perfectamente pueden darse. Es por ello que el manejo de estos valores extremos consistirá en simplemente dejarlos como actualmente están recogidos.

Realizaremos un análisis de valores extremos para la variable numérica __Fare__, realizando un análisis por quartiles:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# generar los quartiles que representan la distribución del conjunto de datos
summary(titanic.data$Fare)

## Calculamos la relación inter quartil (IQR), Q3 - Q1 = IQR()
print(paste("Relación inter quartil (IQR): ",IQR(titanic.data$Fare)),quote = FALSE)

# Grafico de boxplot
gf.boxplot <- boxplot(titanic.data$Fare, main="Boxplot del precio del Boleto (Fare)",
ylab="Fare",col = "bisque")
```

Al inspeccionar las estadísticas arrojadas, para la variable __Fare__, el valor mínimo es 3.17 y el Máximo es 512.33. Si analisamos  la diferencia entre Q1 y el Mínimo es de 4.75, y la diferencia entre Q3 y el Máximo es 481.05; cómo podemos ver la diferencia de Q3 y el máximo es mayor que la diferencias entre Q1 y el mínimo. Estos nos indican que el 25% de los valores superiores es tan más dispersos, que el 75% restante.

Al analizar el grafico de diagrama de cajas (Boxplot), se observa que no hay valores atípicos en el extremo inferior, y por eso el bigote inferior se extiende hasta el valor mínimo, 3.17. En cambio en el extremo superior vemos varios valores atípicos, representados por unos círculos sobre el bigote superior.  

Para detectar los valores atípicos, los bigotes se extendieron hasta un $Mínimo = Q1 - 1.5*IQR$, por debajo de Q1 y hasta un $Máximo = Q3 + 1.5*IQR$, por encima de Q3. Donde __IQR = 23.35__, __Q1 = 7.93__ y __Q3 = 31.28__; Entonces el $Mínimo=7.93–1.5*23.35=-27.01$, donde todos los valores menores a este valor son considerados atípicos, en nuestro caso como no hay valores menores que este, por eso el bigote se extiende hasta el mínimo valor de la variable; Los valores mayores al $Máximo=31.28+1.5*23.35=66.31$ serán considerados atípicos, que son los valores representados en el grafico por los puntos negros.  

Considerando lo anterior, a continuación se muestran los valores atípicos para la variable __Fare__. __Donde Fare > 66.31__:

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Valores extremos encontrados en la variable Fare donde Fare > 66.31
sort(gf.boxplot$out, decreasing = FALSE)
```

No obstante, si revisamos los anteriores datos, y miramos de forma aleatoria los precios de los Ticket podemos ver que los precios mas altos corresponde a los pasajeros de clase alta (Pclass = "Upper"), y son valores que perfectamente pueden darse. Es por ello que el manejo de estos valores extremos consistirá en simplemente dejarlos como actualmente están recogidos.

## Análisis de los datos

## Representación de los resultados a partir de tablas y gráficas.

## Código fuente y dataset


# Recursos

